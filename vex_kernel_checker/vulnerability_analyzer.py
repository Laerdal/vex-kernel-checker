#!/usr/bin/env python3
"""
Vulnerability Analyzer for VEX Kernel Checker.

This module handles the core vulnerability analysis logic, including:
- Architecture compatibility checking
- Driver-specific pattern detection
- Configuration requirement analysis
- Vulnerability state determination
"""

# flake8: noqa: SC200

import time
from typing import Any, Dict, List, Optional, Set

from .base import VexKernelCheckerBase
from .common import (
    Justification,
    Response,
    VulnerabilityAnalysis,
    VulnerabilityState,
    timed_method,
)


class VulnerabilityAnalyzer(VexKernelCheckerBase):
    """Handles vulnerability analysis and architecture compatibility checking."""

    def __init__(self, **kwargs):
        """Initialize the VulnerabilityAnalyzer.
        
        Args:
            **kwargs: Additional keyword arguments passed to the base class.
        """
        super().__init__(**kwargs)
        self._processed_cves = set()
        # Remove hardcoded patterns - will use dynamic analysis instead
        self._arch_patterns = self._init_architecture_patterns()

    def _init_architecture_patterns(self) -> Dict[str, List[str]]:
        """Initialize architecture-specific patterns."""
        return {
            'x86': ['x86', 'intel', 'amd64', 'i386', 'i486', 'i586', 'i686'],
            'x86_64': ['x86_64', 'amd64', 'intel 64', 'x64'],
            'arm': ['arm32', 'armv7', 'armv6', 'arm cortex'],
            'arm64': ['arm64', 'aarch64', 'armv8'],
            'mips': ['mips', 'mips32', 'mips64'],
            'powerpc': ['powerpc', 'ppc', 'ppc32', 'ppc64'],
            'riscv': ['riscv', 'risc-v', 'riscv32', 'riscv64'],
            's390': ['s390', 's390x', 'ibm z'],
            'sparc': ['sparc', 'sparc32', 'sparc64', 'sun'],
            'alpha': ['alpha', 'dec alpha'],
            'ia64': ['ia64', 'itanium'],
            'm68k': ['m68k', 'motorola 68k'],
            'sh': ['superh', 'sh4'],
            'microblaze': ['microblaze'],
            'parisc': ['parisc', 'pa-risc'],
            'xtensa': ['xtensa'],
        }

    @timed_method
    def analyze_cve(
        self,
        cve: Dict,
        kernel_config: List[str],
        kernel_source_path: str,
        cve_manager,
        patch_manager,
        config_analyzer,
    ) -> Optional[VulnerabilityAnalysis]:
        """
        Main method to analyze a CVE for vulnerability.

        Args:
            cve: CVE dictionary with id and description
            kernel_config: List of kernel configuration options
            kernel_source_path: Path to kernel source
            cve_manager: CVE data manager instance
            patch_manager: Patch manager instance
            config_analyzer: Configuration analyzer instance

        Returns:
            VulnerabilityAnalysis or None if no analysis possible
        """
        try:
            # Phase 1: Validate input and check if already processed
            cve_id = self._validate_cve_input(cve)
            if not cve_id:
                return None

            # Phase 2: Fetch CVE details if patch checking enabled
            cve_info = self._fetch_cve_details(cve_id, cve_manager)

            # Phase 3: Check if CVE is kernel-related
            if not self._check_kernel_relevance(cve, cve_id, cve_info, cve_manager):
                return None

            # Phase 4: Try patch-based analysis first
            if self.check_patches and cve_info:
                patch_analysis = self._analyze_patch_content(
                    cve, cve_id, cve_info, patch_manager, config_analyzer, kernel_config, kernel_source_path
                )
                if patch_analysis:
                    return patch_analysis
            elif self.check_patches and not cve_info:
                if self.verbose:
                    print('ðŸ” VulnAnalyzer: check_patches=True but cve_info=None, skipping patch analysis')
            elif not self.check_patches:
                if self.verbose:
                    print('ðŸ” VulnAnalyzer: check_patches=False, skipping patch analysis')

            # Phase 5: Fallback analysis
            fallback_analysis = self._perform_fallback_analysis(
                cve, cve_id, kernel_config, kernel_source_path, config_analyzer
            )
            if fallback_analysis:
                return fallback_analysis

            # Phase 6: Final fallback - no specific analysis possible
            if self.verbose:
                print(f'Unable to determine configuration requirements for {cve_id} - leaving unprocessed')
            return None

        except Exception as e:
            if self.verbose:
                print(f"Error analyzing {cve.get('id', 'unknown')}: {e}")
                import traceback
                traceback.print_exc()
            return None

    @timed_method
    def infer_driver_configs_from_description(
        self, description: str, kernel_source_path: Optional[str] = None, config_analyzer=None
    ) -> Set[str]:
        """
        Dynamically infer driver-specific configuration options from CVE description
        using kernel source analysis instead of hardcoded patterns.
        
        Note: This method is primarily used for fallback analysis when patch content
        is not available. Patch-based analysis is preferred and handled separately.

        Args:
            description: CVE description text
            kernel_source_path: Path to kernel source directory for dynamic analysis
            config_analyzer: ConfigurationAnalyzer instance for source analysis

        Returns:
            Set of configuration options relevant to the detected components
        """
        driver_configs = set()
        description_lower = description.lower()

        # Extract file paths and component names from description
        potential_files = self._extract_file_paths_from_description(description_lower)
        potential_components = self._extract_component_names_from_description(description_lower)

        if self.verbose and (potential_files or potential_components):
            print(f"CVE description analysis - Files: {potential_files}, Components: {potential_components}")

        # If we have kernel source and config analyzer, use dynamic analysis
        if kernel_source_path and config_analyzer:
            # Analyze specific files mentioned in the description
            for file_path in potential_files:
                try:
                    file_configs = config_analyzer.find_config_options_for_file(
                        file_path, kernel_source_path
                    )
                    if file_configs:
                        driver_configs.update(file_configs)
                        if self.verbose:
                            print(f"Dynamic analysis of {file_path} found: {', '.join(file_configs)}")
                except Exception as e:
                    if self.verbose:
                        print(f"Could not analyze {file_path}: {e}")

            # For component names, search for related source files using dynamic analysis
            for component in potential_components:
                try:
                    component_configs = self._find_configs_for_component(
                        component, kernel_source_path, config_analyzer
                    )
                    if component_configs:
                        driver_configs.update(component_configs)
                        if self.verbose:
                            print(f"Component '{component}' dynamic analysis found: {', '.join(component_configs)}")
                except Exception as e:
                    if self.verbose:
                        print(f"Could not analyze component {component}: {e}")

        # Minimal fallback only if no dynamic analysis was possible
        if not driver_configs:
            if self.verbose:
                print("No dynamic analysis possible, using minimal fallback detection")
            driver_configs = self._fallback_subsystem_detection(description_lower)

        return driver_configs

    def _extract_file_paths_from_description(self, description: str) -> Set[str]:
        """Extract potential kernel file paths from CVE description."""
        import re
        
        file_paths = set()
        
        # Common patterns for kernel file paths - more flexible patterns
        patterns = [
            r'drivers/[^/\s]+/[^/\s]+/[^/\s]+\.[ch]',  # drivers/subsystem/driver/file.c
            r'drivers/[^/\s]+/[^/\s]+\.[ch]',          # drivers/subsystem/file.c  
            r'fs/[^/\s]+/[^/\s]+\.[ch]',               # fs/filesystem/file.c
            r'net/[^/\s]+/[^/\s]+\.[ch]',              # net/protocol/file.c
            r'arch/[^/\s]+/[^/\s]+/[^/\s]+\.[ch]',     # arch/architecture/*/file.c
            r'include/[^/\s]+/[^/\s]+\.h',             # include/*/file.h
            r'kernel/[^/\s]+\.[ch]',                   # kernel/file.c
            r'mm/[^/\s]+\.[ch]',                       # mm/file.c
            r'security/[^/\s]+/[^/\s]+\.[ch]',         # security/module/file.c
            # More general patterns
            r'drivers/\S+\.[ch]',                      # any drivers/ file
            r'fs/\S+\.[ch]',                           # any fs/ file
            r'net/\S+\.[ch]',                          # any net/ file
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, description)
            file_paths.update(matches)
            
        return file_paths

    def _extract_component_names_from_description(self, description: str) -> Set[str]:
        """Extract component names that might map to kernel subsystems."""
        import re
        
        components = set()
        
        # Extract driver/module names that commonly appear in CVE descriptions
        patterns = [
            r'(?:in the|the)\s+(\w+)\s+(?:driver|subsystem|module)',
            r'drivers/(\w+)/',
            r'(\w+)\s+(?:filesystem|fs)',
            r'(\w+)\s+network\s+driver',
            r'(\w+)\s+(?:wireless|ethernet)\s+driver',
            r'(\w+):\s+(?:client|server)',  # e.g., "smb: client"
            r'(\w+)\s+(?:client|server)',   # e.g., "nfs client"
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, description, re.IGNORECASE)
            components.update([match.lower() for match in matches])
            
        # Also look for standalone protocol/filesystem names with word boundaries
        standalone_components = [
            'smb', 'cifs', 'nfs', 'ext4', 'xfs', 'btrfs', 
            'usb', 'pci', 'scsi', 'ata', 'nvme', 'mmc',
            'drm', 'i915', 'amdgpu', 'radeon', 'nouveau',
            'bluetooth', 'wifi', 'ethernet', 'wireless',
            'alsa', 'sound', 'input', 'hid',
        ]
        
        description_lower = description.lower()
        for component in standalone_components:
            # Use word boundaries to avoid false matches
            # e.g., "ata" should match "ata subsystem" but not "data" or "create"
            import re
            if re.search(r'\b' + re.escape(component) + r'\b', description_lower):
                components.add(component)
            
        return components

    def _find_configs_for_component(
        self, component: str, kernel_source_path: str, config_analyzer
    ) -> Set[str]:
        """Find configuration options for a specific component using dynamic kernel source analysis."""
        import os
        import glob
        
        configs = set()
        
        # Use dynamic kernel source analysis instead of hardcoded mappings
        if kernel_source_path and os.path.exists(kernel_source_path):
            # Search for component-related files in kernel source
            search_paths = [
                f'drivers/*/{component}*',
                f'drivers/*/*{component}*',
                f'fs/{component}*',
                f'net/{component}*',
                f'arch/*/{component}*',
                f'sound/*/{component}*',
                f'crypto/*/{component}*',
            ]
            
            for search_path in search_paths:
                full_search_path = os.path.join(kernel_source_path, search_path)
                matching_files = glob.glob(full_search_path)
                
                for file_path in matching_files[:10]:  # Limit to avoid too many files
                    if file_path.endswith(('.c', '.h')):
                        relative_path = os.path.relpath(file_path, kernel_source_path)
                        try:
                            file_configs = config_analyzer.find_config_options_for_file(
                                relative_path, kernel_source_path
                            )
                            if file_configs:
                                configs.update(file_configs)
                                if self.verbose:
                                    print(f"Dynamic analysis of {relative_path} found: {', '.join(file_configs)}")
                        except Exception as e:
                            if self.verbose:
                                print(f"Could not analyze {relative_path}: {e}")
                        
        return configs

    def _fallback_subsystem_detection(self, description: str) -> Set[str]:
        """Minimal fallback subsystem detection when dynamic analysis is completely unavailable."""
        configs = set()
        
        # Only use a minimal set of hardcoded patterns as last resort
        # This should rarely be used since we prioritize dynamic patch analysis
        critical_subsystems = {
            # Only the most critical and obvious subsystems
            'cifs': ['CONFIG_CIFS'],
            'smb': ['CONFIG_CIFS'],
            'nfs': ['CONFIG_NFS_FS'],
            'ext4': ['CONFIG_EXT4_FS'],
            'xfs': ['CONFIG_XFS_FS'],
            'btrfs': ['CONFIG_BTRFS_FS'],
        }
        
        import re
        for keyword, config_list in critical_subsystems.items():
            # Use word boundaries to be more precise
            if re.search(r'\b' + re.escape(keyword) + r'\b', description, re.IGNORECASE):
                configs.update(config_list)
                if self.verbose:
                    print(f"Minimal fallback detection: '{keyword}' -> {', '.join(config_list)}")
                    
        return configs

    @timed_method
    def check_architecture_compatibility(
        self,
        cve: Dict,
        cve_info: Optional[Dict] = None,
        patch_content: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Check if a CVE is compatible with the detected system architecture.

        Args:
            cve: CVE dictionary with description and ID
            cve_info: Optional CVE info object with patch URLs
            patch_content: Optional patch content for analysis

        Returns:
            Dictionary with compatibility information
        """
        if not self.arch:
            return {
                'compatible': True,
                'reason': 'No architecture detected',
                'detail': 'Architecture compatibility could not be determined',
            }

        description = cve.get('description', '').lower()
        cve_id = cve.get('id', 'unknown')

        # Check if CVE description mentions specific architectures
        mentioned_archs = []
        for arch, patterns in self._arch_patterns.items():
            for pattern in patterns:
                if pattern in description:
                    mentioned_archs.append(arch)
                    break

        # Remove duplicates and normalize
        mentioned_archs = list(set(mentioned_archs))

        # Normalize current architecture for comparison
        current_arch_normalized = self.arch.lower()
        if current_arch_normalized == 'x86_64':
            current_arch_alternatives = ['x86_64', 'amd64', 'x64']
        elif current_arch_normalized == 'arm64':
            current_arch_alternatives = ['arm64', 'aarch64']
        elif current_arch_normalized == 'powerpc':
            current_arch_alternatives = ['powerpc', 'ppc']
        else:
            current_arch_alternatives = [current_arch_normalized]

        # Check for incompatibility
        if mentioned_archs:
            # Check if any mentioned architecture matches current architecture
            compatible = any(
                mentioned_arch in current_arch_alternatives
                or any(alt in mentioned_arch for alt in current_arch_alternatives)
                for mentioned_arch in mentioned_archs
            )

            if not compatible:
                return {
                    'compatible': False,
                    'reason': f'CVE targets {", ".join(mentioned_archs)} but system is {self.arch}',
                    'detail': f'CVE {cve_id} specifically affects {", ".join(mentioned_archs)} '
                    f'architecture(s), but the current system is {self.arch}',
                }

        # Check patch content for architecture-specific patterns
        if patch_content:
            # Look for architecture-specific directories and files in patch
            arch_paths = [
                'arch/x86',
                'arch/arm',
                'arch/arm64',
                'arch/mips',
                'arch/powerpc',
                'arch/s390',
                'arch/sparc',
            ]

            patch_specific_archs = []
            for arch_path in arch_paths:
                if arch_path in patch_content:
                    arch_name = arch_path.split('/')[1]
                    patch_specific_archs.append(arch_name)

            if patch_specific_archs:
                # Check if current architecture is among the patched architectures
                compatible = any(
                    arch in current_arch_alternatives
                    or any(alt in arch for alt in current_arch_alternatives)
                    for arch in patch_specific_archs
                )

                if not compatible:
                    return {
                        'compatible': False,
                        'reason': f'Patch targets {', '.join(patch_specific_archs)} but system is {self.arch}',
                        'detail': f'CVE {cve_id} patch affects {', '.join(patch_specific_archs)} '
                        f'architecture(s), but the current system is {self.arch}',
                    }

        return {
            'compatible': True,
            'reason': 'Architecture compatible',
            'detail': f'CVE {cve_id} is compatible with {self.arch} architecture',
        }

    @timed_method
    def analyze_config_requirements(
        self, config_options: Set[str], kernel_config: List[str]
    ) -> VulnerabilityAnalysis:
        """
        Analyze if the required configuration options are enabled in the kernel.

        Args:
            config_options: Set of required configuration options
            kernel_config: List of kernel configuration lines

        Returns:
            VulnerabilityAnalysis with the analysis result
        """
        # Separate core driver and filesystem configs from dependencies and architecture configs
        core_driver_filesystem_configs = self._get_core_driver_filesystem_configs(
            config_options
        )
        arch_configs = self._get_arch_specific_configs()

        # Add architecture configs for comprehensive check, but track separately
        all_config_options = set(config_options)
        if arch_configs:
            all_config_options.update(arch_configs)
            if self.verbose and arch_configs:
                print(f"Added architecture-specific configs: {', '.join(arch_configs)}")

        if not core_driver_filesystem_configs:
            return VulnerabilityAnalysis(
                state=VulnerabilityState.IN_TRIAGE,
                justification=Justification.CODE_NOT_PRESENT,
                response=Response.CAN_NOT_FIX,
                detail='No configuration requirements identified',
                timestamp=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            )

        # Parse kernel config into a dictionary
        enabled_configs = set()
        disabled_configs = set()

        for line in kernel_config:
            line = line.strip()
            if line.startswith('CONFIG_') and '=' in line:
                config_name, value = line.split('=', 1)
                if value in ['y', 'm']:
                    enabled_configs.add(config_name)
                elif value == 'n':
                    disabled_configs.add(config_name)
            elif line.startswith('# CONFIG_') and line.endswith(' is not set'):
                # Extract config name from '# CONFIG_NAME is not set'
                config_name = line[2:].split(' is not set')[0]
                disabled_configs.add(config_name)

        # Check core driver and filesystem configs (these are the ones that matter for vulnerability)
        enabled_driver_configs = core_driver_filesystem_configs.intersection(
            enabled_configs
        )
        missing_driver_configs = core_driver_filesystem_configs - enabled_configs

        # Check all configs for comprehensive analysis
        enabled_required = all_config_options.intersection(enabled_configs)
        missing_required = all_config_options - enabled_configs

        if self.verbose:
            print(f"Required configs: {', '.join(sorted(all_config_options))}")
            print(f"Enabled required: {', '.join(sorted(enabled_required))}")
            print(f"Missing required: {', '.join(sorted(missing_required))}")

        # Determine vulnerability state based on CORE DRIVER/FILESYSTEM configuration analysis
        # Architecture and dependency configs are checked but don't affect the vulnerability determination
        if not missing_driver_configs:
            # All required core driver/filesystem configs are enabled
            return VulnerabilityAnalysis(
                state=VulnerabilityState.EXPLOITABLE,
                justification=Justification.REQUIRES_CONFIGURATION,
                response=Response.CAN_NOT_FIX,
                detail=f"All required driver/filesystem configurations are enabled: {', '.join(sorted(enabled_driver_configs))}",
                timestamp=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            )
        elif enabled_driver_configs:
            # Some but not all required core driver/filesystem configs are enabled
            return VulnerabilityAnalysis(
                state=VulnerabilityState.IN_TRIAGE,
                justification=Justification.REQUIRES_CONFIGURATION,
                response=Response.CAN_NOT_FIX,
                detail=(
                    f'Partial driver/filesystem configuration match. '
                    f"Enabled: {', '.join(sorted(enabled_driver_configs))}. "
                    f"Missing: {', '.join(sorted(missing_driver_configs))}"
                ),
                timestamp=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            )
        else:
            # No required core driver/filesystem configs are enabled - this is the key case for CIFS
            return VulnerabilityAnalysis(
                state=VulnerabilityState.NOT_AFFECTED,
                justification=Justification.REQUIRES_CONFIGURATION,
                response=Response.WILL_NOT_FIX,
                detail=f"Required driver/filesystem configs not enabled: {', '.join(sorted(missing_driver_configs))}",
                timestamp=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            )

    def _get_arch_specific_configs(self) -> Set[str]:
        """Get architecture-specific configuration options from detected architecture."""
        arch_configs = set()

        if self.arch:
            # Add the main architecture config
            arch_config_map = {
                'arm': 'CONFIG_ARM',
                'arm64': 'CONFIG_ARM64',
                'x86': 'CONFIG_X86',
                'x86_64': 'CONFIG_X86',
                'mips': 'CONFIG_MIPS',
                'powerpc': 'CONFIG_POWERPC',
                'riscv': 'CONFIG_RISCV',
                's390': 'CONFIG_S390',
                'sparc': 'CONFIG_SPARC',
                'sparc64': 'CONFIG_SPARC64',
            }

            if self.arch in arch_config_map:
                arch_configs.add(arch_config_map[self.arch])

            # Add common architecture-specific configs
            arch_specific_mappings = {
                'arm': ['CONFIG_ARM', 'CONFIG_ARM_THUMB', 'CONFIG_ARM_LPAE'],
                'arm64': [
                    'CONFIG_ARM64',
                    'CONFIG_ARM64_4K_PAGES',
                    'CONFIG_ARM64_VA_BITS_48',
                ],
                'x86': ['CONFIG_X86', 'CONFIG_X86_32'],
                'x86_64': ['CONFIG_X86', 'CONFIG_X86_64', 'CONFIG_64BIT'],
                'mips': ['CONFIG_MIPS', 'CONFIG_MIPS32_R1'],
                'powerpc': ['CONFIG_PPC', 'CONFIG_POWERPC'],
                'riscv': ['CONFIG_RISCV'],
                's390': ['CONFIG_S390'],
                'sparc': ['CONFIG_SPARC'],
                'sparc64': ['CONFIG_SPARC64', 'CONFIG_64BIT'],
            }

            if self.arch in arch_specific_mappings:
                arch_configs.update(arch_specific_mappings[self.arch])

        return arch_configs

    def _get_core_driver_filesystem_configs(self, driver_configs: Set[str]) -> Set[str]:
        """
        Extract core driver and filesystem configs excluding common dependencies and build system configs.

        Args:
            driver_configs: Full set of driver and filesystem configs including dependencies

        Returns:
            Set of core driver and filesystem configs (excluding common dependencies and build configs)
        """
        # Filter out architecture, build system, and common dependency configs
        filtered_configs = set()
        
        for config in driver_configs:
            # Skip architecture-specific configs
            if any(arch_pattern in config for arch_pattern in [
                'CONFIG_ARCH_', 'CONFIG_ARM64_', 'CONFIG_X86_', 'CONFIG_ARM_',
                'CONFIG_MIPS_', 'CONFIG_POWERPC_', 'CONFIG_S390_', 'CONFIG_SPARC_'
            ]):
                continue
                
            # Skip build system and toolchain configs
            if any(build_pattern in config for build_pattern in [
                'CONFIG_CC_', 'CONFIG_LD_', 'CONFIG_AS_', 'CONFIG_CLANG_',
                'CONFIG_GCC_', 'CONFIG_LLD_', 'CONFIG_BFD_', 'CONFIG_LTO_',
                'CONFIG_CFI_', 'CONFIG_DEBUG_INFO', 'CONFIG_FRAME_',
                'CONFIG_FTRACE_', 'CONFIG_FUNCTION_', 'CONFIG_HAVE_',
                'CONFIG_HAS_', 'CONFIG_KALLSYMS', 'CONFIG_MODVERSIONS',
                'CONFIG_MODULE_SIG', 'CONFIG_STACK_', 'CONFIG_ZERO_',
                'CONFIG_INIT_STACK_', 'CONFIG_RETHUNK', 'CONFIG_RELR',
                'CONFIG_SHADOW_', 'CONFIG_TOOLS_', 'CONFIG_TRIM_',
                'CONFIG_HEADERS_', 'CONFIG_GDB_', 'CONFIG_READABLE_',
                'CONFIG_STRIP_', 'CONFIG_EXPERT', 'CONFIG_MMU',
                'CONFIG_OF_', 'CONFIG_BPF', 'CONFIG_ORPHAN_'
            ]):
                continue
                
            # Skip numeric configs (like CONFIG_110000, CONFIG_120000)
            if config.startswith('CONFIG_') and config[8:].isdigit():
                continue
                
            # Skip very generic configs
            if config in {
                'CONFIG_MODULES', 'CONFIG_DEBUG_KERNEL', 'CONFIG_FRAME_POINTER'
            }:
                continue
                
            # Keep driver, filesystem, and protocol specific configs (but not generic network)
            if any(relevant_pattern in config for relevant_pattern in [
                'CONFIG_CIFS', 'CONFIG_SMB', 'CONFIG_NFS', 'CONFIG_EXT4',
                'CONFIG_XFS', 'CONFIG_BTRFS', 'CONFIG_USB', 'CONFIG_SCSI',
                'CONFIG_ATA', 'CONFIG_DRM', 'CONFIG_SND', 'CONFIG_BT',
                'CONFIG_WIRELESS'
            ]):
                filtered_configs.add(config)
                continue
                
            # Keep specific driver configs but exclude generic network configs
            if config.startswith('CONFIG_') and config not in {
                'CONFIG_NET', 'CONFIG_INET', 'CONFIG_IPV4', 'CONFIG_IPV6', 
                'CONFIG_TCP', 'CONFIG_UDP'
            }:
                # Keep configs that look like specific drivers or filesystems
                # (usually have underscores and are not generic)
                if '_' in config[8:] and len(config) > 12:
                    filtered_configs.add(config)

        # If no core configs remain after filtering, look for minimal relevant configs
        if not filtered_configs:
            # Return only the most relevant configs that we know matter
            relevant_configs = {
                'CONFIG_CIFS', 'CONFIG_SMB', 'CONFIG_NFS_FS', 'CONFIG_EXT4_FS',
                'CONFIG_XFS_FS', 'CONFIG_BTRFS_FS'
            }
            return driver_configs.intersection(relevant_configs)

        return filtered_configs

    def _validate_cve_input(self, cve: Dict) -> Optional[str]:
        """Validate CVE input and return CVE ID."""
        cve_id = cve.get('id', '')
        if not cve_id:
            if self.verbose:
                print('Missing CVE ID - skipping analysis')
            return None

        if cve_id in self._processed_cves:
            if self.verbose:
                print(f'Skipping {cve_id} - already processed')
            return None

        self._processed_cves.add(cve_id)
        if self.verbose:
            print(f'\n--- Analyzing {cve_id} ---')

        return cve_id

    def _fetch_cve_details(self, cve_id: str, cve_manager) -> Optional[Dict]:
        """Fetch CVE details from NVD API if patch checking is enabled."""
        if not self.check_patches:
            if self.verbose:
                print(f'ðŸ” VulnAnalyzer: check_patches={self.check_patches}, skipping CVE fetch')
            return None

        if self.verbose:
            print('ðŸ” Step 1/4: Fetching CVE details from NVD API...')
            print(f'ðŸ” VulnAnalyzer: check_patches={self.check_patches}, calling cve_manager.fetch_cve_details')

        cve_info = cve_manager.fetch_cve_details(cve_id)

        if cve_info:
            if self.verbose:
                print(f'ðŸ” VulnAnalyzer: Successfully got CVE info for {cve_id}')
        elif self.verbose:
            print(f'ðŸ” VulnAnalyzer: Could not fetch CVE details for {cve_id} - proceeding with VEX description analysis')

        return cve_info

    def _check_kernel_relevance(self, cve: Dict, cve_id: str, cve_info: Optional[Dict], cve_manager) -> bool:
        """Check if CVE is kernel-related."""
        if self.analyze_all_cves:
            return True

        if cve_info:
            if self.verbose:
                print('ðŸ” Step 2/4: Checking if CVE is kernel-related...')
            if not cve_manager.is_kernel_related_cve(cve_info):
                if self.verbose:
                    print(f'CVE {cve_id} is not kernel-related - skipping analysis')
                return False
        else:
            # For CVEs without detailed info, check description for kernel relevance
            description = cve.get('description', '').lower()
            kernel_keywords = [
                'linux kernel', 'kernel', 'drivers/', 'net/', 'fs/', 'arch/', 'kernel.org',
            ]
            if not any(keyword in description for keyword in kernel_keywords):
                if self.verbose:
                    print(f'CVE {cve_id} description does not appear kernel-related - skipping analysis')
                return False

        return True

    def _analyze_patch_content(
        self, cve: Dict, cve_id: str, cve_info: Dict, patch_manager, config_analyzer, kernel_config: List[str], kernel_source_path: str
    ) -> Optional[VulnerabilityAnalysis]:
        """Analyze patch content and configuration requirements."""
        if self.verbose:
            print('ðŸ” Step 3/4: Extracting and fetching patch content...')
            print('ðŸ” VulnAnalyzer: Calling patch_manager.extract_patch_url')

        patch_url = patch_manager.extract_patch_url(cve_info)

        if not patch_url:
            return None

        if self.verbose:
            print(f'ðŸ” VulnAnalyzer: Found patch URL: {patch_url}')
            print('ðŸ” VulnAnalyzer: Calling patch_manager.fetch_patch_content_with_github_priority')

        # Fetch patch content
        patch_info = patch_manager.fetch_patch_content_with_github_priority(patch_url)

        if not patch_info:
            return None

        if self.verbose:
            print(f'ðŸ” VulnAnalyzer: Successfully fetched patch content for {cve_id}')

        # Early architecture compatibility check
        arch_compatibility = self.check_architecture_compatibility(cve, cve_info, patch_info)
        if not arch_compatibility['compatible']:
            if self.verbose:
                print(f"CVE not compatible with current architecture: {arch_compatibility['reason']}")

            return VulnerabilityAnalysis(
                state=VulnerabilityState.NOT_AFFECTED,
                justification=Justification.REQUIRES_ENVIRONMENT,
                response=Response.WILL_NOT_FIX,
                detail=arch_compatibility['detail'],
                timestamp=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            )

        # Analyze configuration requirements
        return self._analyze_source_files(cve_id, patch_info, patch_manager, config_analyzer, kernel_config, kernel_source_path)

    def _analyze_source_files(
        self, cve_id: str, patch_info: Dict, patch_manager, config_analyzer, kernel_config: List[str], kernel_source_path: str
    ) -> Optional[VulnerabilityAnalysis]:
        """Analyze source files from patch for configuration requirements."""
        if self.verbose:
            print('ðŸ” Step 4/4: Analyzing configuration requirements...')

        # Extract source files from patch content
        source_files = patch_manager.extract_sourcefiles(patch_info)
        
        # Also extract file paths directly from patch content
        patch_content = patch_info.get('content', '') if isinstance(patch_info, dict) else str(patch_info)
        additional_files = self._extract_files_from_patch_content(patch_content)
        
        # Combine both sets of files
        all_files = set(source_files) if source_files else set()
        all_files.update(additional_files)

        if not all_files:
            if self.verbose:
                print('No source files found in patch content')
            return None

        if self.verbose:
            print(f'Analyzing {len(all_files)} source files from patch')

        all_config_options = set()
        source_file_list = list(all_files)[:20]  # Limit to 20 files

        for i, source_file in enumerate(source_file_list):
            try:
                if self.verbose and len(source_file_list) > 1:
                    print(f'   ðŸ“ Analyzing file {i+1}/{len(source_file_list)}: {source_file}')

                # Use the dynamic kernel source analysis
                configs = config_analyzer.find_config_options_for_file(source_file, kernel_source_path)
                if configs:
                    all_config_options.update(configs)
                    if self.verbose:
                        print(f'      Found configs: {", ".join(configs)}')

            except Exception as exc:
                if self.verbose:
                    print(f'Error analyzing source file {source_file}: {exc}')

        if all_config_options:
            if self.verbose:
                print(f'Patch analysis found {len(all_config_options)} config options: {", ".join(sorted(all_config_options))}')
            config_analysis = self.analyze_config_requirements(all_config_options, kernel_config)
            if config_analysis:
                return config_analysis

        return None

    def _extract_files_from_patch_content(self, patch_content: str) -> Set[str]:
        """Extract file paths directly from patch content (diff format)."""
        import re
        
        files = set()
        
        if not patch_content:
            return files
            
        # Look for diff headers like:
        # --- a/fs/cifs/file.c
        # +++ b/fs/cifs/file.c
        # diff --git a/drivers/net/ethernet/intel/e1000/e1000_main.c b/drivers/net/ethernet/intel/e1000/e1000_main.c
        
        patterns = [
            r'--- a/([^\s]+)',                    # --- a/path/to/file.c
            r'\+\+\+ b/([^\s]+)',                 # +++ b/path/to/file.c  
            r'diff --git a/([^\s]+) b/([^\s]+)',  # diff --git a/file.c b/file.c
            r'@@.*@@\s+([^\s]+)',                 # @@ context @@ path/to/file.c (some formats)
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, patch_content)
            if isinstance(matches[0], tuple) if matches else False:
                # Handle tuples from git diff pattern
                for match_tuple in matches:
                    files.update([f for f in match_tuple if f and not f.startswith('/dev/null')])
            else:
                files.update([f for f in matches if f and not f.startswith('/dev/null')])
        
        # Filter to only kernel source files
        kernel_files = set()
        for file_path in files:
            if any(file_path.startswith(prefix) for prefix in [
                'drivers/', 'fs/', 'net/', 'kernel/', 'mm/', 'arch/', 
                'sound/', 'crypto/', 'security/', 'block/', 'lib/'
            ]) and file_path.endswith(('.c', '.h')):
                kernel_files.add(file_path)
        
        return kernel_files

    def _perform_fallback_analysis(
        self, cve: Dict, cve_id: str, kernel_config: List[str], kernel_source_path: str, config_analyzer
    ) -> Optional[VulnerabilityAnalysis]:
        """Perform driver-specific and general fallback analysis."""
        description = cve.get('description', '').lower()

        # Driver-specific fallback analysis using dynamic kernel source analysis
        driver_configs = self.infer_driver_configs_from_description(
            description, kernel_source_path, config_analyzer
        )
        if driver_configs:
            if self.verbose:
                print(f'Dynamic analysis: found {len(driver_configs)} relevant configs')
            config_analysis = self.analyze_config_requirements(driver_configs, kernel_config)
            if config_analysis:
                return config_analysis

        # General fallback - check if description contains specific vulnerability indicators
        vulnerability_keywords = [
            'use-after-free', 'buffer overflow', 'null pointer dereference',
            'memory corruption', 'heap overflow', 'stack overflow', 'double free',
            'out-of-bounds', 'format string', 'integer overflow'
        ]

        if any(keyword in description for keyword in vulnerability_keywords):
            if self.verbose:
                print(f'Found vulnerability keywords in {cve_id} description')
            return VulnerabilityAnalysis(
                state=VulnerabilityState.IN_TRIAGE,
                justification=Justification.REQUIRES_CONFIGURATION,
                response=Response.WILL_NOT_FIX,
                detail='CVE contains vulnerability indicators but specific configuration requirements could not be determined',
                timestamp=time.strftime('%Y-%m-%dT%H:%M:%SZ', time.gmtime()),
            )

        return None
